{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8564a9a9",
   "metadata": {},
   "source": [
    "# Integration and reference mapping with multigrate\n",
    "\n",
    "In this notebook, we demonstrate how to use Multigrate with scArches: we build a trimodal reference atlas with Multigrate by integrating CITE-seq and multiome data, and map unimodal as well as multimodal queries onto the reference. We use publically available datasets from NeurIPS 2021 workshop https://openproblems.bio/neurips_2021/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6130eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
      "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
      " captum (see https://github.com/pytorch/captum).\n",
      "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
      "/root/anaconda3/envs/multigrate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/anaconda3/envs/multigrate/lib/python3.10/site-packages/flax/core/frozen_dict.py:169: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(\n",
      "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n"
     ]
    }
   ],
   "source": [
    "import scarches as sca\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import muon\n",
    "import gdown\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "from os.path import join as pj\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4), fontsize=8)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "984f27cc",
   "metadata": {},
   "source": [
    "## Data preprocessing\n",
    "First, we download the datasets and split them into AnnData objects corresponding to individual modalities: gene expression (RNA) and protein abundance (ADT) for CITE-seq, and gene expression (RNA) and chromatin opennes (ATAC) for multiome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "474616d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'wnn'\n",
    "method = 'multigrate'\n",
    "experiment = 'multigrate_offline'\n",
    "result_path = pj('../../../result', task, experiment)\n",
    "data_root = 'path/data/raw/rna+adt'\n",
    "save_path = '../multigrate/offline_cellmask/'\n",
    "batch_key='batch'\n",
    "label_key='l1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "657b7321",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "rna = sc.read_h5ad(pj(data_root, task,'rna_cellmask.h5ad'))\n",
    "adt = sc.read_h5ad(pj(data_root, task,'adt_cellmask.h5ad'))\n",
    "rna\n",
    "muon.prot.pp.clr(adt)\n",
    "adt\n",
    "## Prep the input AnnData object\n",
    "adata = sca.models.organize_multiome_anndatas(\n",
    "    adatas = [[rna], [adt]],    # a list of anndata objects per modality, RNA-seq always goes first\n",
    "    layers = [[None], [None]], # if need to use data from .layers, if None use .X\n",
    ")\n",
    "adata\n",
    "\n",
    "sca.models.MultiVAE.setup_anndata(\n",
    "    adata,\n",
    "    categorical_covariate_keys=[batch_key],\n",
    "    rna_indices_end=adata.uns['modality_lengths'][0],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a9007d7",
   "metadata": {},
   "source": [
    "# Offline Training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e3c57c1",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "\n",
    "Next, we initialize the model. If using raw counts for RNA-seq, use NB loss, if normalized counts, use MSE. For ADT we use CLR-normalized counts and MSE loss. We need to specify `mmd='marginal'` and set the coeficient to the integration loss if we want to later map unimodal data onto this reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8cb4aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/200:  11%|â–ˆ         | 22/200 [01:59<16:40,  5.62s/it, loss=1.67e+03, v_num=1]"
     ]
    }
   ],
   "source": [
    "model = sca.models.MultiVAE(\n",
    "    adata, \n",
    "    losses=['nb', 'mse'],\n",
    "    loss_coefs={'kl': 1e-1,\n",
    "               'integ': 3000,\n",
    "               },\n",
    "    z_dim=32,\n",
    "    # integrate_on='Modality',\n",
    "    mmd='marginal',\n",
    ")\n",
    "model.train()\n",
    "# to load trained model\n",
    "# state = torch.load('/opt/data/private/xx/code/MIRACLE/comparison/results/wnn/multigrate/offline_cellmask/model.pt')\n",
    "# state.keys()\n",
    "# for k, v in state['attr_dict'].items():\n",
    "#     # print(k)\n",
    "#     model.__dict__[k] = v\n",
    "# model.module.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12e4dfe0",
   "metadata": {},
   "source": [
    "### save latent and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3bee91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pj('../', method, 'offline')):\n",
    "    os.makedirs(pj('../', method, 'offline'))\n",
    "model.save(pj('../', method, experiment),overwrite=True)\n",
    "model.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(6142, 32)\n",
      "1\n",
      "(3978, 32)\n",
      "2\n",
      "(4103, 32)\n",
      "3\n",
      "(5172, 32)\n",
      "4\n",
      "(4205, 32)\n",
      "5\n",
      "(5265, 32)\n",
      "6\n",
      "(8770, 32)\n",
      "7\n",
      "(8578, 32)\n"
     ]
    }
   ],
   "source": [
    "for i in pd.unique(adata.obs[batch_key]):\n",
    "\n",
    "    if type(i)=='str':\n",
    "        j = int(i[1])-1\n",
    "        print(j)\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/z/joint'%(j))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/z/joint'%(j)))\n",
    "        print(adata[adata.obs[batch_key]=='P'+str(j+1)].obsm['latent'].shape)\n",
    "        pd.DataFrame(adata[adata.obs[batch_key]=='P'+str(j+1)].obsm['latent']).to_csv(pj(result_path, 'default/predict','subset_%d/z/joint'%(j),'00.csv'), index=False, header=False)\n",
    "    else:\n",
    "        print(i)\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/z/joint'%(i))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/z/joint'%(i)))\n",
    "        print(adata[adata.obs['batch']==i].obsm['latent'].shape)\n",
    "        pd.DataFrame(adata[adata.obs['batch']==i].obsm['latent']).to_csv(pj(result_path, 'default/predict','subset_%d/z/joint'%(i),'00.csv'), index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65764add",
   "metadata": {},
   "source": [
    "### save reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2a8ae712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6142\n",
      "1\n",
      "10120\n",
      "2\n",
      "14223\n",
      "3\n",
      "19395\n",
      "4\n",
      "23600\n",
      "5\n",
      "28865\n",
      "6\n",
      "37635\n",
      "7\n",
      "46213\n"
     ]
    }
   ],
   "source": [
    "adata = sca.models.organize_multiome_anndatas(\n",
    "    adatas = [[rna], [adt]],    # a list of anndata objects per modality, RNA-seq always goes first\n",
    "    layers = [[None], [None]], # if need to use data from .layers, if None use .X\n",
    ")\n",
    "adata\n",
    "\n",
    "sca.models.MultiVAE.setup_anndata(\n",
    "    adata,\n",
    "    categorical_covariate_keys=[batch_key],\n",
    "    rna_indices_end=adata.uns['modality_lengths'][0],\n",
    ")\n",
    "\n",
    "\n",
    "adata = model._validate_anndata(adata)\n",
    "scdl = model._make_data_loader(adata=adata)\n",
    "\n",
    "rna_r = torch.Tensor([])\n",
    "adt_r = torch.Tensor([])\n",
    "\n",
    "for tensors in scdl: \n",
    "    x_r = model.module.sample(tensors)\n",
    "    rna_r = torch.concat([rna_r, x_r[0].cpu()])\n",
    "    adt_r = torch.concat([adt_r, x_r[1].cpu()])\n",
    "l = 0\n",
    "for i in pd.unique(adata.obs[batch_key]):\n",
    "    if type(i)==str:\n",
    "        j = int(i[1])-1\n",
    "        print(j)\n",
    "        if j==0:\n",
    "            rna_batch = rna_r[0:adata[adata.obs[batch_key]=='P'+str(j+1)].shape[0]]\n",
    "            adt_batch = adt_r[0:adata[adata.obs[batch_key]=='P'+str(j+1)].shape[0]]\n",
    "        else:\n",
    "            rna_batch = rna_r[l:l+adata[adata.obs[batch_key]=='P'+str(j+1)].shape[0]]\n",
    "            adt_batch = adt_r[l:l+adata[adata.obs[batch_key]=='P'+str(j+1)].shape[0]]\n",
    "        l = l+adata[adata.obs[batch_key]=='P'+str(j+1)].shape[0]\n",
    "        print(l)\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x_bc/rna'%(j))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x_bc/rna'%(j)))\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x_bc/adt'%(j))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x_bc/adt'%(j)))\n",
    "        pd.DataFrame(rna_batch).to_csv(pj(result_path, 'default/predict','subset_%d/x_bc/rna'%(j),'00.csv'), index=False, header=False)\n",
    "        pd.DataFrame(adt_batch).to_csv(pj(result_path, 'default/predict','subset_%d/x_bc/adt'%(j),'00.csv'), index=False, header=False)\n",
    "    else:\n",
    "        print(i)\n",
    "        j = i\n",
    "        if j==0:\n",
    "            rna_batch = rna_r[0:adata[adata.obs[batch_key]==(j)].shape[0]]\n",
    "            adt_batch = adt_r[0:adata[adata.obs[batch_key]==(j)].shape[0]]\n",
    "        else:\n",
    "            rna_batch = rna_r[l:l+adata[adata.obs[batch_key]==(j)].shape[0]]\n",
    "            adt_batch = adt_r[l:l+adata[adata.obs[batch_key]==(j)].shape[0]]\n",
    "        l = l+adata[adata.obs[batch_key]==j].shape[0]\n",
    "        print(l)\n",
    "        \n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x_bc/rna'%(i))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x_bc/rna'%(i)))\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x_bc/adt'%(i))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x_bc/adt'%(i)))\n",
    "        pd.DataFrame(rna_batch).to_csv(pj(result_path, 'default/predict','subset_%d/x_bc/rna'%(i),'00.csv'), index=False, header=False)\n",
    "        pd.DataFrame(adt_batch).to_csv(pj(result_path, 'default/predict','subset_%d/x_bc/adt'%(i),'00.csv'), index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1cd4209f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([0, 224])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adt_batch.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f208f75",
   "metadata": {},
   "source": [
    "### save latent and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecce50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(pj('../', method, experiment)):\n",
    "    os.makedirs(pj('../', method, experiment))\n",
    "model.save(pj('../', method, experiment),overwrite=True)\n",
    "model.get_latent_representation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5555bb5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "(6142, 32)\n",
      "1\n",
      "(3978, 32)\n",
      "2\n",
      "(4103, 32)\n",
      "3\n",
      "(5172, 32)\n",
      "4\n",
      "(4205, 32)\n",
      "5\n",
      "(5265, 32)\n",
      "6\n",
      "(8770, 32)\n",
      "7\n",
      "(8578, 32)\n"
     ]
    }
   ],
   "source": [
    "for i in pd.unique(adata.obs[batch_key]):\n",
    "\n",
    "    if type(i)=='str':\n",
    "        j = int(i[1])-1\n",
    "        print(j)\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/z/joint'%(j))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/z/joint'%(j)))\n",
    "        print(adata[adata.obs[batch_key]=='P'+str(j+1)].obsm['latent'].shape)\n",
    "        pd.DataFrame(adata[adata.obs[batch_key]=='P'+str(j+1)].obsm['latent']).to_csv(pj(result_path, 'default/predict','subset_%d/z/joint'%(j),'00.csv'), index=False, header=False)\n",
    "    else:\n",
    "        print(i)\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/z/joint'%(i))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/z/joint'%(i)))\n",
    "        print(adata[adata.obs['batch']==i].obsm['latent'].shape)\n",
    "        pd.DataFrame(adata[adata.obs['batch']==i].obsm['latent']).to_csv(pj(result_path, 'default/predict','subset_%d/z/joint'%(i),'00.csv'), index=False, header=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1713cec",
   "metadata": {},
   "source": [
    "### save reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "adata = model._validate_anndata(adata)\n",
    "scdl = model._make_data_loader(adata=adata)\n",
    "\n",
    "rna_r = torch.Tensor([])\n",
    "adt_r = torch.Tensor([])\n",
    "\n",
    "for tensors in scdl: \n",
    "    x_r = model.module.sample(tensors)\n",
    "    rna_r = torch.concat([rna_r, x_r[0].cpu()])\n",
    "    adt_r = torch.concat([adt_r, x_r[1].cpu()])\n",
    "\n",
    "rna_r = sc.AnnData(np.array(rna_r))\n",
    "rna_r.obs_names = adata.obs_names\n",
    "rna_r.obs =  adata.obs\n",
    "\n",
    "adt_r = sc.AnnData(np.array(adt_r))\n",
    "adt_r.obs_names = adata.obs_names\n",
    "adt_r.obs =  adata.obs\n",
    "\n",
    "for i in pd.unique(adata.obs[batch_key]):\n",
    "    if type(i)=='str':\n",
    "        j = int(i[1])-1\n",
    "        print(j)\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x/rna'%(j))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x/rna'%(j)))\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x/adt'%(j))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x/adt'%(j)))\n",
    "        pd.DataFrame(rna_r[rna_r.obs[batch_key]=='P'+str(j+1)].X).to_csv(pj(result_path, 'default/predict','subset_%d/x/rna'%(j),'00.csv'), index=False, header=False)\n",
    "        pd.DataFrame(rna_r[rna_r.obs[batch_key]=='P'+str(j+1)].X).to_csv(pj(result_path, 'default/predict','subset_%d/x/adt'%(j),'00.csv'), index=False, header=False)\n",
    "    else:\n",
    "        print(i)\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x/rna'%(i))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x/rna'%(i)))\n",
    "        if not os.path.exists(pj(result_path, 'default/predict','subset_%d/x/adt'%(i))):\n",
    "            os.makedirs(pj(result_path, 'default/predict','subset_%d/x/adt'%(i)))\n",
    "        pd.DataFrame(adata[adata.obs[batch_key]==i].X).to_csv(pj(result_path, 'default/predict','subset_%d/x/rna'%(i),'00.csv'), index=False, header=False)\n",
    "        pd.DataFrame(adata[adata.obs[batch_key]==i].X).to_csv(pj(result_path, 'default/predict','subset_%d/x/adt'%(i),'00.csv'), index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multigrate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "641a2530f28f7cd7d5e4f28713f9b400052dfdd26ab3bd0e911554dae36d0601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
