{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8564a9a9",
   "metadata": {},
   "source": [
    "# Integration and reference mapping with multigrate\n",
    "\n",
    "In this notebook, we demonstrate how to use Multigrate with scArches: we build a trimodal reference atlas with Multigrate by integrating CITE-seq and multiome data, and map unimodal as well as multimodal queries onto the reference. We use publically available datasets from NeurIPS 2021 workshop https://openproblems.bio/neurips_2021/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6130eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:In order to use the mouse gastrulation seqFISH datsets, please install squidpy (see https://github.com/scverse/squidpy).\n",
      "WARNING:root:In order to use sagenet models, please install pytorch geometric (see https://pytorch-geometric.readthedocs.io) and \n",
      " captum (see https://github.com/pytorch/captum).\n",
      "INFO:lightning_fabric.utilities.seed:Global seed set to 0\n",
      "/root/anaconda3/envs/multigrate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/anaconda3/envs/multigrate/lib/python3.10/site-packages/flax/core/frozen_dict.py:169: FutureWarning: jax.tree_util.register_keypaths is deprecated, and will be removed in a future release. Please use `register_pytree_with_keys()` instead.\n",
      "  jax.tree_util.register_keypaths(\n",
      "WARNING:root:mvTCR is not installed. To use mvTCR models, please install it first using \"pip install mvtcr\"\n"
     ]
    }
   ],
   "source": [
    "import scarches as sca\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import numpy as np\n",
    "import muon\n",
    "import gdown\n",
    "import json\n",
    "import argparse\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "import multigrate as mtg\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "sc.set_figure_params(figsize=(4, 4), fontsize=8)\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35f1876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnn_cellmask\n",
      "0 rna\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 6142 × 4050\n",
      "    obs: 'batch'\n",
      "0 adt\n",
      "AnnData object with n_obs × n_vars = 6142 × 224\n",
      "    obs: 'batch'\n",
      "1 rna\n",
      "AnnData object with n_obs × n_vars = 3978 × 4050\n",
      "    obs: 'batch'\n",
      "1 adt\n",
      "AnnData object with n_obs × n_vars = 3978 × 224\n",
      "    obs: 'batch'\n",
      "2 rna\n",
      "AnnData object with n_obs × n_vars = 4103 × 4050\n",
      "    obs: 'batch'\n",
      "2 adt\n",
      "AnnData object with n_obs × n_vars = 4103 × 224\n",
      "    obs: 'batch'\n",
      "3 rna\n",
      "AnnData object with n_obs × n_vars = 5172 × 4050\n",
      "    obs: 'batch'\n",
      "3 adt\n",
      "AnnData object with n_obs × n_vars = 5172 × 224\n",
      "    obs: 'batch'\n",
      "4 rna\n",
      "AnnData object with n_obs × n_vars = 4205 × 4050\n",
      "    obs: 'batch'\n",
      "4 adt\n",
      "AnnData object with n_obs × n_vars = 4205 × 224\n",
      "    obs: 'batch'\n",
      "5 rna\n",
      "AnnData object with n_obs × n_vars = 5265 × 4050\n",
      "    obs: 'batch'\n",
      "5 adt\n",
      "AnnData object with n_obs × n_vars = 5265 × 224\n",
      "    obs: 'batch'\n",
      "6 rna\n",
      "AnnData object with n_obs × n_vars = 8770 × 4050\n",
      "    obs: 'batch'\n",
      "6 adt\n",
      "AnnData object with n_obs × n_vars = 8770 × 224\n",
      "    obs: 'batch'\n",
      "7 rna\n",
      "AnnData object with n_obs × n_vars = 8578 × 4050\n",
      "    obs: 'batch'\n",
      "7 adt\n",
      "AnnData object with n_obs × n_vars = 8578 × 224\n",
      "    obs: 'batch'\n",
      "3451\n",
      "224\n",
      "View of AnnData object with n_obs × n_vars = 6142 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 3978 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 4103 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 5172 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 4205 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 5265 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 8770 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 8578 × 3451\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 6142 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 3978 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 4103 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 5172 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 4205 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 5265 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 8770 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "View of AnnData object with n_obs × n_vars = 8578 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts'\n",
      "7.1011143\n",
      "6.0205474\n",
      "7.6970735\n",
      "7.3633714\n",
      "6.6217556\n",
      "6.218634\n",
      "7.1964025\n",
      "6.9267793\n",
      "{'rna': [AnnData object with n_obs × n_vars = 6142 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts', AnnData object with n_obs × n_vars = 3978 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts', AnnData object with n_obs × n_vars = 4103 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts', AnnData object with n_obs × n_vars = 5172 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts', AnnData object with n_obs × n_vars = 4205 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts', AnnData object with n_obs × n_vars = 5265 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts', AnnData object with n_obs × n_vars = 8770 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts', AnnData object with n_obs × n_vars = 8578 × 3451\n",
      "    obs: 'batch'\n",
      "    uns: 'log1p'\n",
      "    layers: 'counts'], 'adt': [AnnData object with n_obs × n_vars = 6142 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr', AnnData object with n_obs × n_vars = 3978 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr', AnnData object with n_obs × n_vars = 4103 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr', AnnData object with n_obs × n_vars = 5172 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr', AnnData object with n_obs × n_vars = 4205 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr', AnnData object with n_obs × n_vars = 5265 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr', AnnData object with n_obs × n_vars = 8770 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr', AnnData object with n_obs × n_vars = 8578 × 224\n",
      "    obs: 'batch'\n",
      "    layers: 'counts', 'clr'], 'atac': [None, None, None, None, None, None, None, None]}\n",
      "{'rna': ['counts', 'counts', 'counts', 'counts', 'counts', 'counts', 'counts', 'counts'], 'adt': ['clr', 'clr', 'clr', 'clr', 'clr', 'clr', 'clr', 'clr'], 'atac': [None, None, None, None, None, None, None, None]}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--task', type=str, default='wnn_cellmask',\n",
    "    help=\"Choose a task\")\n",
    "parser.add_argument('--experiment', type=str, default='ref_mapping',\n",
    "    help=\"\")\n",
    "parser.add_argument('--kl', type=float, default=1e-1,\n",
    "    help=\"\")\n",
    "parser.add_argument('--integ', type=int, default=3000,\n",
    "    help=\"\")\n",
    "parser.add_argument('--inner', type=int, default=1,\n",
    "    help=\"\")\n",
    "# o = parser.parse_args()\n",
    "o, _ = parser.parse_known_args() \n",
    "\n",
    "task = o.task\n",
    "data_root = '/dev/shm/processed/'+task\n",
    "print(o.task)\n",
    "\n",
    "data = {'rna':[], 'adt':[], 'atac':[]}\n",
    "layers = {'rna':[], 'adt':[], 'atac':[]}\n",
    "# labels = []\n",
    "mask = {'rna':[], 'adt':[]}\n",
    "mods = []\n",
    "\n",
    "def creat_h5ad(mat, obs_names, label, batch):\n",
    "    adata = sc.AnnData(mat)\n",
    "    adata.obs_names = obs_names\n",
    "    # adata.obs['l1'] = label\n",
    "    adata.obs['batch'] = batch\n",
    "    adata.obs['batch']  = adata.obs['batch'].astype('category')\n",
    "    return adata\n",
    "\n",
    "for i in range(8):\n",
    "    m = []\n",
    "    d = {}\n",
    "    p = data_root+'/subset_'+str(i)\n",
    "    \n",
    "    # label = pd.read_csv(label_path[i], sep=',', index_col=0)\n",
    "    for m in ['rna', 'adt', 'atac']:\n",
    "        if os.path.exists(p+'/mat/'+m+'.csv'):\n",
    "            mods.append(m)\n",
    "            print(i, m)\n",
    "\n",
    "            mat = pd.read_csv(p+'/mat/'+m+'.csv', sep=',', index_col=0)\n",
    "            cellnames = pd.read_csv(p+'/cell_names.csv', sep=',', index_col=0).values.flatten()\n",
    "            # label.index = cellnames\n",
    "            adata = creat_h5ad(mat, cellnames, None, i)\n",
    "\n",
    "            print(adata)\n",
    "\n",
    "            if m != 'atac':\n",
    "                mask[m].append(pd.read_csv(p+'/mask/'+m+'.csv', index_col=0))\n",
    "            if m=='adt':\n",
    "                adata.layers['counts'] = adata.X.copy()\n",
    "            elif m=='rna':\n",
    "                adata.layers['counts'] = adata.X.copy()\n",
    "            elif m=='atac':\n",
    "                adata.layers['counts'] = adata.X.copy()\n",
    "                \n",
    "            data[m].append(adata)\n",
    "        else:\n",
    "            data[m].append(None)\n",
    "        \n",
    "\n",
    "# %%\n",
    "if o.inner:\n",
    "    final_mask = {'rna':None, 'adt':None}\n",
    "    for m in ['rna', 'adt']:\n",
    "        for mk in  mask[m]:\n",
    "            if final_mask[m] is None:\n",
    "                final_mask[m] = mk.values.astype('bool')[0]\n",
    "            else:\n",
    "                final_mask[m] = final_mask[m] & mk.values.astype('bool')[0]\n",
    "        print(final_mask[m].sum())\n",
    "\n",
    "    rna_dim = None\n",
    "    for m in ['rna', 'adt']:\n",
    "        for i in range(len(data[m])):\n",
    "            if data[m][i] is not None:\n",
    "                data[m][i] = data[m][i][:, final_mask[m]]   \n",
    "                print(data[m][i])\n",
    "\n",
    "for m in ['rna', 'adt', 'atac']:\n",
    "    for i in range(8):\n",
    "        if data[m][i] is not None and m=='rna':\n",
    "            rna = data[m][i]\n",
    "            sc.pp.normalize_total(rna, target_sum=1e4)\n",
    "            sc.pp.log1p(rna)\n",
    "            layers[m].append('counts')\n",
    "\n",
    "        elif data[m][i] is not None and m=='adt':\n",
    "            adt = data[m][i]\n",
    "            adt.X = adt.layers['counts'].copy()\n",
    "            muon.prot.pp.clr(adt)\n",
    "            print(np.max(adt.X))\n",
    "            adt.layers['clr'] = adt.X.copy()\n",
    "            layers[m].append('clr')\n",
    "\n",
    "        elif data[m][i] is not None and m=='atac':\n",
    "            atac = data[m][i]\n",
    "            muon.atac.pp.tfidf(atac, scale_factor=1e4)\n",
    "            atac\n",
    "            atac.layers['tf-idf'] = atac.X.copy()\n",
    "            atac.X = atac.layers['counts'].copy()\n",
    "            sc.pp.normalize_total(atac, target_sum=1e4)\n",
    "            sc.pp.log1p(atac)\n",
    "            atac.layers['log-norm'] = atac.X.copy()\n",
    "            layers[m].append('log-norm')\n",
    "\n",
    "        else:\n",
    "            layers[m].append(None)\n",
    "print(data)\n",
    "print(layers)\n",
    "\n",
    "# %%\n",
    "mod = []\n",
    "losses = []\n",
    "for i in ['rna', 'atac', 'adt']:\n",
    "    if i in mods:\n",
    "        mod.append(i)\n",
    "        if i=='rna':\n",
    "            losses.append('nb')\n",
    "        else:\n",
    "            losses.append('mse')\n",
    "\n",
    "# adata = sca.models.organize_multiome_anndatas(\n",
    "#     adatas = [data['rna'], data['atac'], data['adt']],    # a list of anndata objects per modality, RNA-seq always goes first\n",
    "#     layers = [layers['rna'], layers['atac'], layers['adt']], # if need to use data from .layers, if None use .X\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9e98f819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_path = [\n",
    "#     './data/sct/atac+rna+adt/dogma_label_mask/P1/label_seurat/l1.csv',\n",
    "#     './data/sct/atac+rna+adt/dogma_label_mask/P2/label_seurat/l1.csv',\n",
    "#     './data/sct/atac+rna+adt/dogma_label_mask/P3/label_seurat/l1.csv',\n",
    "#     './data/sct/atac+rna+adt/dogma_label_mask/P4/label_seurat/l1.csv',\n",
    "#     './data/sct/atac+rna+adt/tea_label_mask/P5/label_seurat/l1.csv',\n",
    "#     './data/sct/atac+rna+adt/tea_label_mask/P6/label_seurat/l1.csv',\n",
    "#     './data/sct/atac+rna+adt/tea_label_mask/P7/label_seurat/l1.csv',\n",
    "#     './data/sct/atac+rna+adt/tea_label_mask/P8/label_seurat/l1.csv']\n",
    "# labels = []\n",
    "# for i in label_path:\n",
    "#     labels.append(pd.read_csv(i, index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5b3c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_names_all = []\n",
    "for i in range(8):\n",
    "    p = data_root+'/subset_'+str(i)\n",
    "    cell_names_all.append(pd.read_csv(p+'/cell_names.csv', sep=',', index_col=0).values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4899698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(8):\n",
    "#     labels[i].index = cell_names_all[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e3c57c1",
   "metadata": {},
   "source": [
    "## Initialize the model\n",
    "\n",
    "Next, we initialize the model. If using raw counts for RNA-seq, use NB loss, if normalized counts, use MSE. For ADT we use CLR-normalized counts and MSE loss. We need to specify `mmd='marginal'` and set the coeficient to the integration loss if we want to later map unimodal data onto this reference."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2afbd017",
   "metadata": {},
   "source": [
    "## Map and Query\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8689c877",
   "metadata": {},
   "source": [
    "## create triple modality model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16f77d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rna = data['rna']\n",
    "# adt = data['adt']\n",
    "# atac = data['atac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e68481a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 46213 × 3675\n",
      "    obs: 'batch', 'group'\n",
      "    var: 'modality'\n",
      "    uns: 'modality_lengths'\n",
      "    layers: 'counts'\n"
     ]
    }
   ],
   "source": [
    "adata_all = mtg.data.organize_multiome_anndatas(\n",
    "    adatas = [data['rna'],  data['adt']],    # a list of anndata objects per modality, RNA-seq always goes first\n",
    "    layers = [layers['rna'], layers['adt']], # if need to use data from .layers, if None use .X\n",
    ")\n",
    "print(adata_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7534a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all = adata_all[np.concatenate(cell_names_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c5c5925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_all.obs['label'] = pd.concat(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e88adc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View of AnnData object with n_obs × n_vars = 6142 × 3675\n",
      "    obs: 'batch', 'group'\n",
      "    var: 'modality'\n",
      "    uns: 'modality_lengths'\n",
      "    layers: 'counts'\n"
     ]
    }
   ],
   "source": [
    "adata_ref = adata_all[(adata_all.obs['batch']==0)]\n",
    "print(adata_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb182ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "sca.models.MultiVAE.setup_anndata(\n",
    "    adata_ref,\n",
    "    categorical_covariate_keys=['batch'],\n",
    "    rna_indices_end=adata_ref.uns['modality_lengths'][0],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81f7808b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sca.models.MultiVAE(\n",
    "    adata_ref,\n",
    "    losses=['nb', 'mse',],\n",
    "    loss_coefs={'kl': 1e-1,\n",
    "                'integ': 3000,\n",
    "                },\n",
    "    z_dim=32,\n",
    "    integrate_on='batch',\n",
    "    mmd='marginal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8695aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████| 500/500 [06:47<00:00,  1.24it/s, loss=1.35e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=500` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500: 100%|██████████| 500/500 [06:47<00:00,  1.23it/s, loss=1.35e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model.train(use_gpu=True, max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b390e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_latent_representation()\n",
    "os.makedirs('./result/wnn_cellmask/multigrate_obo/default/predict/subset_0/z/joint/')\n",
    "pd.DataFrame(adata_ref[adata_ref.obs['batch']==0].obsm['latent']).to_csv('./result/wnn_cellmask/multigrate_obo/default/predict/subset_0/z/joint/00.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "8b8b36cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model2.save('./result/teadog_paired_full_label_mask_new/multigrate_obo/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab59c253",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:08<00:00,  2.83it/s, loss=1.56e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:08<00:00,  2.90it/s, loss=1.56e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:09<00:00,  2.92it/s, loss=1.5e+03, v_num=1] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:09<00:00,  2.89it/s, loss=1.5e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:27<00:00,  2.22it/s, loss=1.43e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:27<00:00,  2.29it/s, loss=1.43e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:13<00:00,  2.84it/s, loss=1.83e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:13<00:00,  2.72it/s, loss=1.83e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:29<00:00,  2.10it/s, loss=2.25e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [01:29<00:00,  2.23it/s, loss=2.25e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [02:23<00:00,  1.41it/s, loss=2.34e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [02:23<00:00,  1.40it/s, loss=2.34e+03, v_num=1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
      "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
      "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
      "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
      "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [02:22<00:00,  1.44it/s, loss=2.16e+03, v_num=1]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pytorch_lightning.utilities.rank_zero:`Trainer.fit` stopped: `max_epochs=200` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/200: 100%|██████████| 200/200 [02:22<00:00,  1.41it/s, loss=2.16e+03, v_num=1]\n"
     ]
    }
   ],
   "source": [
    "model2 = model\n",
    "for i in range(1, 8):\n",
    "    adata_q = adata_all[(adata_all.obs['batch']==i)]\n",
    "    sca.models.MultiVAE.setup_anndata(\n",
    "    adata_q,\n",
    "    categorical_covariate_keys=['batch'],\n",
    "    rna_indices_end=adata_q.uns['modality_lengths'][0])\n",
    "    q_model = sca.models.MultiVAE.load_query_data(adata_q, model2)\n",
    "    q_model.train(weight_decay=0)\n",
    "    q_model.get_latent_representation(adata=adata_q)\n",
    "    if not os.path.exists('./result/wnn_cellmask/multigrate_obo/default/predict/subset_%d/z/joint/'%(i)):\n",
    "        os.makedirs('./result/wnn_cellmask/multigrate_obo/default/predict/subset_%d/z/joint/'%(i))\n",
    "    pd.DataFrame(adata_q.obsm['latent']).to_csv('./result/wnn_cellmask/multigrate_obo/default/predict/subset_%d/z/joint/00.csv'%(i), index=False, header=False)\n",
    "    model2 = q_model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multigrate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "641a2530f28f7cd7d5e4f28713f9b400052dfdd26ab3bd0e911554dae36d0601"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
